{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hate_Universe = pd.read_csv('./Data/Hate_Universe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan6 = Hate_Universe[(Hate_Universe['Day'] >= '2021-01-01') & (Hate_Universe['Day']< '2021-01-11')]\n",
    "Nov7 = Hate_Universe[(Hate_Universe['Day'] >= '2020-11-01') & (Hate_Universe['Day']< '2020-11-11')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan6 = Jan6.dropna(subset=['Target'])\n",
    "Nov7 = Nov7.dropna(subset= ['Target'])\n",
    "\n",
    "# Converting to Datetime format\n",
    "Jan6['Day'] = pd.to_datetime(Jan6['Day'])\n",
    "Nov7['Day'] = pd.to_datetime(Nov7['Day'])\n",
    "\n",
    "# Group by 'Day' and count the number of rows for each day\n",
    "daily_counts_Jan6 = Jan6.groupby('Day').size()\n",
    "daily_counts_Nov7 = Nov7.groupby('Day').size()\n",
    "\n",
    "# Calculate the increase relative to the first day\n",
    "relative_increase_Jan6 = ((daily_counts_Jan6 - daily_counts_Jan6.iloc[0])/(daily_counts_Jan6.iloc[0]))*100.00\n",
    "relative_increase_Nov7 = ((daily_counts_Nov7 - daily_counts_Nov7.iloc[0])/(daily_counts_Nov7.iloc[0]))*100.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(relative_increase_Jan6.index, relative_increase_Jan6.values, marker='o', linestyle='-', alpha=0.7, markersize=6)\n",
    "plt.axvline(x=pd.Timestamp('2021-01-06'), color='red', linestyle='--', alpha=0.7)\n",
    "plt.text(pd.Timestamp('2021-01-06'), relative_increase_Jan6.loc['2021-01-06'], 'Capitol Attack', color='red', verticalalignment='bottom', horizontalalignment='right')\n",
    "plt.title('Increase in Hate Links Relative to Jan 1, 2021')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Increase in Number of Hate Links (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.gca().set_yticklabels(['{:.0f}%'.format(x) for x in plt.gca().get_yticks()])  # Add '%' symbol to y-axis labels\n",
    "plt.tight_layout()\n",
    "plt.grid(False)  # Removing gridlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(relative_increase_Nov7.index, relative_increase_Nov7.values, marker='o', linestyle='-', alpha=0.7, markersize=6)\n",
    "plt.axvline(x=pd.Timestamp('2020-11-03'), color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.axvline(x=pd.Timestamp('2020-11-07'), color='red', linestyle='--', alpha=0.7)\n",
    "plt.text(pd.Timestamp('2020-11-03'), relative_increase_Nov7.loc['2020-11-03'], 'Election Day', color='red', verticalalignment='bottom', horizontalalignment='right')\n",
    "\n",
    "plt.text(pd.Timestamp('2020-11-07'), relative_increase_Nov7.loc['2020-11-07'], 'President Elect Declared', color='red', verticalalignment='bottom', horizontalalignment='right')\n",
    "plt.title('Increase in Hate Links Relative to Nov 1, 2020')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Increase in Number of Hate Links (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.gca().set_yticklabels(['{:.0f}%'.format(x) for x in plt.gca().get_yticks()])  # Add '%' symbol to y-axis labels\n",
    "plt.tight_layout()\n",
    "plt.grid(False)  # Removing gridlines\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pre_election = Hate_Universe[(Hate_Universe['Day'] >= '2020-11-01') & (Hate_Universe['Day']< '2020-11-03')]\n",
    "\n",
    "post_election = Hate_Universe[(Hate_Universe['Day'] >=  '2020-11-03') & (Hate_Universe['Day']< '2020-11-05')]\n",
    "\n",
    "\n",
    "pre_Jan6 = Hate_Universe[(Hate_Universe['Day'] >= '2021-01-01') & (Hate_Universe['Day'] < '2021-01-06')]\n",
    "\n",
    "\n",
    "post_Jan6 = Hate_Universe[(Hate_Universe['Day']  >= '2021-01-06') & (Hate_Universe['Day'] < '2021-01-11')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_election = pre_election.dropna(subset=['Target'])\n",
    "post_election = post_election.dropna(subset= ['Target'])\n",
    "pre_Jan6 = pre_Jan6.dropna(subset=['Target'])\n",
    "post_Jan6 = post_Jan6.dropna(subset= ['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_pre_Nov7= nx.from_pandas_edgelist(pre_election, 'Source', 'Target',  create_using=nx.Graph())\n",
    "Graph_post_Nov7 = nx.from_pandas_edgelist(post_election, 'Source', 'Target',  create_using=nx.Graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_percentage_change(pre, post):\n",
    "    return ((post - pre) / pre) * 100\n",
    "\n",
    "# Calculate properties for Graph_pre_Jan6\n",
    "pre_density = nx.density(Graph_pre_Nov7)\n",
    "pre_cliques = list(nx.find_cliques(Graph_pre_Nov7))\n",
    "pre_max_clique_size = max(len(clique) for clique in pre_cliques)\n",
    "pre_num_communities = nx.number_connected_components(Graph_pre_Nov7)\n",
    "pre_largest_community = max(len(c) for c in nx.connected_components(Graph_pre_Nov7))\n",
    "pre_clustering_coefficient = nx.average_clustering(Graph_pre_Nov7)\n",
    "pre_assortativity = nx.assortativity.degree_assortativity_coefficient(Graph_pre_Nov7)\n",
    "\n",
    "# Calculate properties for Graph_post_Jan6\n",
    "post_density = nx.density(Graph_post_Nov7)\n",
    "post_cliques = list(nx.find_cliques(Graph_post_Nov7))\n",
    "post_max_clique_size = max(len(clique) for clique in post_cliques)\n",
    "post_num_communities = nx.number_connected_components(Graph_post_Nov7)\n",
    "post_largest_community = max(len(c) for c in nx.connected_components(Graph_post_Nov7))\n",
    "post_clustering_coefficient = nx.average_clustering(Graph_post_Nov7)\n",
    "post_assortativity = nx.assortativity.degree_assortativity_coefficient(Graph_post_Nov7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Property': ['Density', 'Number of Cliques', 'Max Clique Size', 'Number of Communities',\n",
    "                 'Size of Largest Community', 'Clustering Coefficient', 'Assortativity'],\n",
    "    'Pre_election': [pre_density, len(pre_cliques), pre_max_clique_size, pre_num_communities,\n",
    "                 pre_largest_community, pre_clustering_coefficient, pre_assortativity],\n",
    "    'Post_election': [post_density, len(post_cliques), post_max_clique_size, post_num_communities,\n",
    "                  post_largest_community, post_clustering_coefficient, post_assortativity]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "for prop in data['Property']:\n",
    "    pre_value = df.loc[df['Property'] == prop, 'Pre_election'].values[0]\n",
    "    post_value = df.loc[df['Property'] == prop, 'Post_election'].values[0]\n",
    "    percentage_change = calculate_percentage_change(pre_value, post_value)\n",
    "    df.loc[df['Property'] == prop, 'Percentage Change'] = percentage_change\n",
    "\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_pre_Jan6 = nx.from_pandas_edgelist(pre_Jan6, 'Source', 'Target',  create_using=nx.Graph())\n",
    "Graph_post_Jan6 = nx.from_pandas_edgelist(post_Jan6, 'Source', 'Target',  create_using=nx.Graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate properties for Graph_pre_Jan6\n",
    "pre_density = nx.density(Graph_pre_Jan6)\n",
    "pre_cliques = list(nx.find_cliques(Graph_pre_Jan6))\n",
    "pre_max_clique_size = max(len(clique) for clique in pre_cliques)\n",
    "pre_num_communities = nx.number_connected_components(Graph_pre_Jan6)\n",
    "pre_largest_community = max(len(c) for c in nx.connected_components(Graph_pre_Jan6))\n",
    "pre_clustering_coefficient = nx.average_clustering(Graph_pre_Jan6)\n",
    "pre_assortativity = nx.assortativity.degree_assortativity_coefficient(Graph_pre_Jan6)\n",
    "\n",
    "# Calculate properties for Graph_post_Jan6\n",
    "post_density = nx.density(Graph_post_Jan6)\n",
    "post_cliques = list(nx.find_cliques(Graph_post_Jan6))\n",
    "post_max_clique_size = max(len(clique) for clique in post_cliques)\n",
    "post_num_communities = nx.number_connected_components(Graph_post_Jan6)\n",
    "post_largest_community = max(len(c) for c in nx.connected_components(Graph_post_Jan6))\n",
    "post_clustering_coefficient = nx.average_clustering(Graph_post_Jan6)\n",
    "post_assortativity = nx.assortativity.degree_assortativity_coefficient(Graph_post_Jan6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Property': ['Density', 'Number of Cliques', 'Max Clique Size', 'Number of Communities',\n",
    "                 'Size of Largest Community', 'Clustering Coefficient', 'Assortativity'],\n",
    "    'Pre_Jan6': [pre_density, len(pre_cliques), pre_max_clique_size, pre_num_communities,\n",
    "                 pre_largest_community, pre_clustering_coefficient, pre_assortativity],\n",
    "    'Post_Jan6': [post_density, len(post_cliques), post_max_clique_size, post_num_communities,\n",
    "                  post_largest_community, post_clustering_coefficient, post_assortativity]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "for prop in data['Property']:\n",
    "    pre_value = df.loc[df['Property'] == prop, 'Pre_Jan6'].values[0]\n",
    "    post_value = df.loc[df['Property'] == prop, 'Post_Jan6'].values[0]\n",
    "    percentage_change = calculate_percentage_change(pre_value, post_value)\n",
    "    df.loc[df['Property'] == prop, 'Percentage Change'] = percentage_change\n",
    "\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Hate Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Nov7 = pd.read_csv('./Data/df_Nov7_hate_type.csv')\n",
    "df_jan6 = pd.read_csv('./Data/df_jan6_hate_type.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pre_jan6 = df_jan6[(df_jan6['Day'] >= '2021-01-01') & (df_jan6['Day'] <= '2021-01-05')]\n",
    "Post_jan6 = df_jan6[(df_jan6['Day'] >= '2021-01-06') & (df_jan6['Day'] <= '2021-01-10')]\n",
    "Pre_Nov7 = df_Nov7[(df_Nov7['Day'] >= '2020-11-02') & (df_Nov7['Day'] <= '2020-11-06')]\n",
    "Post_Nov7 = df_Nov7[(df_Nov7['Day'] >= '2020-11-07') & (df_Nov7['Day'] <= '2020-11-11')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_columns = ['religion_prediction', 'race_prediction', 'gender_prediction',\n",
    "                   'giso_prediction', 'immigration_prediction', 'ein_prediction', \n",
    "                   'antisemitism_prediction', 'SNS Source']\n",
    "\n",
    "# Group by 'SNS' column and sum the boolean columns\n",
    "hate_counts_pre = Pre_jan6[boolean_columns].groupby('SNS Source').sum()\n",
    "\n",
    "# Group by 'SNS' column and sum the boolean columns\n",
    "hate_counts_post = Post_jan6[boolean_columns].groupby('SNS Source').sum()\n",
    "\n",
    "# Display the counts of hate types for each SNS\n",
    "hate_counts_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_change = ((hate_counts_post - hate_counts_pre) / (hate_counts_pre +1)) * 100\n",
    "percentage_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pre = hate_counts_pre.sum()\n",
    "total_post = hate_counts_post.sum()\n",
    "\n",
    "# Calculate the percentage change without considering the SNS\n",
    "percentage_change_total = ((total_post - total_pre) / total_pre) * 100\n",
    "\n",
    "# Display the percentage change\n",
    "print(percentage_change_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"prediction\" and replace it with \"hate\" in the x-axis labels\n",
    "x_labels = [label.replace('_prediction', ' Hate') for label in percentage_change_total.index]\n",
    "# Plotting the percentage change\n",
    "# Plotting the percentage change\n",
    "plt.figure(figsize=(10, 6))\n",
    "percentage_change_total.plot(kind='bar', color='skyblue')\n",
    "plt.title('Change in Hate Type after January 6 Capitol attack')\n",
    "plt.ylabel('Percentage Increase (%)')\n",
    "plt.xticks(range(len(x_labels)), x_labels, rotation=0, ha='center')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_columns = ['religion_prediction', 'race_prediction', 'gender_prediction',\n",
    "                   'giso_prediction', 'immigration_prediction', 'ein_prediction', \n",
    "                   'antisemitism_prediction', 'SNS Source']\n",
    "\n",
    "# Group by 'SNS' column and sum the boolean columns\n",
    "hate_counts_pre = Pre_Nov7[boolean_columns].groupby('SNS Source').sum()\n",
    "\n",
    "# Group by 'SNS' column and sum the boolean columns\n",
    "hate_counts_post = Post_Nov7[boolean_columns].groupby('SNS Source').sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_change = ((hate_counts_post - hate_counts_pre) / (hate_counts_pre +1) ) * 100\n",
    "percentage_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pre = hate_counts_pre.sum()\n",
    "total_post = hate_counts_post.sum()\n",
    "\n",
    "# Calculate the percentage change without considering the SNS\n",
    "percentage_change_total = ((total_post - total_pre) / total_pre) * 100\n",
    "\n",
    "# Display the percentage change\n",
    "print(percentage_change_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"prediction\" and replace it with \"hate\" in the x-axis labels\n",
    "x_labels = [label.replace('_prediction', ' Hate') for label in percentage_change_total.index]\n",
    "# Plotting the percentage change\n",
    "# Plotting the percentage change\n",
    "plt.figure(figsize=(10, 6))\n",
    "percentage_change_total.plot(kind='bar', color='skyblue')\n",
    "plt.title('Change in Hate Type after January 6 Capitol attack')\n",
    "plt.ylabel('Percentage Increase (%)')\n",
    "plt.xticks(range(len(x_labels)), x_labels, rotation=0, ha='center')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hate_Universe = pd.read_csv('./Data/Hate_Universe.csv')\n",
    "Daily_count_flavors_df = pd.read_csv('./Data/Daily_count_flavors_df.csv', index_col='Day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SNS_columns  = Hate_Universe['SNS Source'].unique().tolist()\n",
    "print(SNS_columns)\n",
    "Daily_count_sns_df = pd.DataFrame()\n",
    "\n",
    "for column in SNS_columns:\n",
    "\n",
    "    true_counts = Hate_Universe[Hate_Universe['SNS Source'] == column].groupby('Day').size()\n",
    "    Daily_count_sns_df[column] = true_counts\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correlations = {}\n",
    "for col1 in Daily_count_flavors_df.columns:\n",
    "    for col2 in Daily_count_sns_df.columns:\n",
    "        correlation = Daily_count_flavors_df[col1].corr(Daily_count_sns_df[col2])\n",
    "        correlations[(col1, col2)] = correlation\n",
    "\n",
    "for pair, correlation in correlations.items():\n",
    "    print(f\"Correlation between {pair[0]} and {pair[1]}: {correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns1, columns2 = zip(*correlations.keys())\n",
    "\n",
    "# Extract correlation values\n",
    "correlation_values = list(correlations.values())\n",
    "\n",
    "# Create a DataFrame from the correlation values with columns as the original column names\n",
    "correlation_df = pd.DataFrame({'Column1': columns1, 'Column2': columns2, 'Correlation': correlation_values})\n",
    "\n",
    "# Pivot the DataFrame to create a correlation matrix\n",
    "correlation_matrix = correlation_df.pivot(index='Column1', columns='Column2', values='Correlation')\n",
    "\n",
    "# Remove the 'Instagram' column and row from the correlation matrix\n",
    "\n",
    "correlation_matrix = correlation_matrix.drop('Instagram', axis=1)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap between daily edge and hate type count across different SNS')\n",
    "plt.xlabel('Social Networking Site')\n",
    "plt.ylabel('Hate Type Detected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Telegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNS_Hate_Core = pd.read_csv(\"./Data/SNS_Hate_Core.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pre_election_sns = SNS_Hate_Core[(SNS_Hate_Core['Day'] >= '2020-11-01') & (SNS_Hate_Core['Day']<= '2020-11-03')]\n",
    "\n",
    "post_election_sns = SNS_Hate_Core[(SNS_Hate_Core['Day'] >  '2020-11-03') & (SNS_Hate_Core['Day']<= '2020-11-07')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_pre_election= nx.from_pandas_edgelist(pre_election_sns, 'SNS Source', 'SNS Target',  create_using=nx.MultiDiGraph())\n",
    "Graph_post_election = nx.from_pandas_edgelist(post_election_sns, 'SNS Source', 'SNS Target',  create_using=nx.MultiDiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for graph in [Graph_pre_election, Graph_post_election]:\n",
    "    indegree_dict = dict(graph.in_degree())\n",
    "    outdegree_dict = dict(graph.out_degree())\n",
    "\n",
    "\n",
    "    indegree_values = list(indegree_dict.values())\n",
    "    outdegree_values = list(outdegree_dict.values())\n",
    "    node_names = list(graph.nodes())\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(indegree_values, outdegree_values, color='blue', alpha=0.5)\n",
    "    plt.xlabel('Indegree')\n",
    "    plt.ylabel('Outdegree')\n",
    "    plt.title(f'Scatterplot of Indegree vs Outdegree for {graph} hate core')\n",
    "    plt.grid(True)\n",
    "\n",
    "    for i, name in enumerate(node_names):\n",
    "        plt.annotate(name, (indegree_values[i], outdegree_values[i]))\n",
    "\n",
    "\n",
    "    # Determine the range for the diagonal line\n",
    "    max_value = max(max(indegree_values), max(outdegree_values))\n",
    "    min_value = min(min(indegree_values), min(outdegree_values))\n",
    "\n",
    "    # Plot diagonal line\n",
    "    plt.plot([min_value, max_value], [min_value, max_value], color='red', linestyle='--')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_pre_election = Graph_pre_election.degree('TG')\n",
    "degree_post_election = Graph_post_election.degree('TG')\n",
    "\n",
    "# 2. Calculate the increase in degree\n",
    "increase_in_degree = ((degree_post_election - degree_pre_election)/degree_pre_election)*100\n",
    "\n",
    "print(\"Increase in degree of node 'TG':\", increase_in_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_in_links_pre_election = sum(dict(Graph_pre_election.in_degree()).values())\n",
    "total_out_links_pre_election = sum(dict(Graph_pre_election.out_degree()).values())\n",
    "\n",
    "total_in_links_post_election = sum(dict(Graph_post_election.in_degree()).values())\n",
    "total_out_links_post_election = sum(dict(Graph_post_election.out_degree()).values())\n",
    "\n",
    "# Calculate the in-degree and out-degree of node \"TG\" for both graphs\n",
    "in_degree_pre_election_TG = Graph_pre_election.in_degree('TG')\n",
    "out_degree_pre_election_TG = Graph_pre_election.out_degree('TG')\n",
    "\n",
    "in_degree_post_election_TG = Graph_post_election.in_degree('TG')\n",
    "out_degree_post_election_TG = Graph_post_election.out_degree('TG')\n",
    "\n",
    "# Calculate the percentages\n",
    "percent_in_links_pre_election = (in_degree_pre_election_TG / total_in_links_pre_election) * 100\n",
    "percent_out_links_pre_election = (out_degree_pre_election_TG / total_out_links_pre_election) * 100\n",
    "\n",
    "percent_in_links_post_election = (in_degree_post_election_TG / total_in_links_post_election) * 100\n",
    "percent_out_links_post_election = (out_degree_post_election_TG / total_out_links_post_election) * 100\n",
    "\n",
    "print(\"Percentage of in-links of node 'TG' in Graph_pre_election:\", percent_in_links_pre_election)\n",
    "print(\"Percentage of out-links of node 'TG' in Graph_pre_election:\", percent_out_links_pre_election)\n",
    "\n",
    "print(\"Percentage of in-links of node 'TG' in Graph_post_election:\", percent_in_links_post_election)\n",
    "print(\"Percentage of out-links of node 'TG' in Graph_post_election:\", percent_out_links_post_election)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
